# TP Machine Learning - BIHAR 2025 (Arnaud THERY)

Projet d'Ã©valuation des modules Machine Learning II, Deep Learning I & II pour l'annÃ©e 2024-2025.

## ğŸ“‹ Description du Projet

Ce repository contient **trois sous-projets indÃ©pendants** de Machine Learning/Deep Learning :

| Sous-Projet                 | Module | Description                                             | Status      |
| --------------------------- | ------ | ------------------------------------------------------- | ----------- |
| **ğŸŒ¡ï¸ Time Series**          | ML II  | PrÃ©diction de tempÃ©rature (ARIMA/SARIMA/RF)             | âœ… ComplÃ©tÃ© |
| **ğŸŒ½ Image Classification** | DL I   | Classification d'images de maÃ¯s (CNN/Transfer Learning) | âœ… ComplÃ©tÃ© |

## ğŸ—ï¸ Architecture & Flux de DonnÃ©es

### Time Series (ML II)

```
Open-Meteo API â†’ AgrÃ©gation 3h â†’ Feature Engineering â†’ [ARIMA/SARIMA/RF] â†’ PrÃ©dictions
                                                              â†“
                                                        Ã‰valuation (RMSE/MAE)
```

### Image Classification (DL I)

```
Kaggle Dataset â†’ PrÃ©traitement (224Ã—224) â†’ Augmentation â†’ [CNN/VGG16/ResNet] â†’ Classification
                                                                  â†“
                                                            LIME (ExplicabilitÃ©)
```

## ğŸ› ï¸ Technologies UtilisÃ©es

| **Technologie**         | Usage                                  |
| ----------------------- | -------------------------------------- |
| **Python 3.10+**        | Langage principal                      |
| **NumPy, Pandas**       | Manipulation de donnÃ©es                |
| **Matplotlib, Seaborn** | Visualisation                          |
| **Scikit-learn**        | ML classique (RF, GradientBoosting)    |
| **Statsmodels**         | ModÃ¨les statistiques (ARIMA/SARIMA)    |
| **PyTorch**             | Deep Learning (CNN, Transfer Learning) |
| **LIME**                | ExplicabilitÃ© des modÃ¨les              |
| **Jupyter Notebook**    | ExpÃ©rimentation interactive            |

## ğŸ“‚ Structure du Repository

```
TP_ML/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bihar_time_series.ipynb       # âœ… ML II - PrÃ©diction tempÃ©rature
â”‚   â””â”€â”€ corn_classification.ipynb     # âœ… DL I - Classification images
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ corn_images/                  # Dataset images maÃ¯s
â”œâ”€â”€ model/
â”‚   â””â”€â”€ registry/                     # ModÃ¨les entraÃ®nÃ©s sÃ©rialisÃ©s
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ monitoring.py                 # Scripts de visualisation
â”‚   â””â”€â”€ output/                       # Graphiques gÃ©nÃ©rÃ©s
â”œâ”€â”€ api/                              # â³ FastAPI (Ã  venir pour MLOps)
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt                  # DÃ©pendances Python
â”œâ”€â”€ TP.md                            # Ã‰noncÃ© du TP
â””â”€â”€ README.md                        # Ce fichier
```

## ğŸš€ Installation & ExÃ©cution Locale

### 1. Cloner le repository

```bash
git clone https://github.com/2024-2025-estia-bihar/TP_ML_Arnaud_THERY.git
cd TP_ML_Arnaud_THERY
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Lancer Jupyter Notebook

```bash
jupyter notebook
```

Puis ouvrir le notebook souhaitÃ© dans `notebooks/`.

## ğŸ“Š Sous-Projets DÃ©taillÃ©s

### ğŸŒ¡ï¸ Time Series Forecasting (ML II)

**Objectif:** DÃ©velopper un modÃ¨le de prÃ©diction de tempÃ©rature Ã  2 mÃ¨tres du sol avec un horizon de 24 heures et un pas de temps de 3 heures.

#### 1ï¸âƒ£ Acquisition des DonnÃ©es

- âœ… **Source:** Open-Meteo Historical Weather API
- âœ… **Localisation:** Ajaccio, France (41.9276Â°N, 8.7381Â°E)
- âœ… **PÃ©riode:** 2015-2024 (10 ans d'historique - dÃ©terminÃ©e via analyse exploratoire)
- âœ… **Variables:** Temperature 2m (Â°C), Relative Humidity 2m (%)
- âœ… **VÃ©rification donnÃ©es manquantes:** Interpolation linÃ©aire appliquÃ©e si nÃ©cessaire

#### 2ï¸âƒ£ Transformation de la SÃ©rie Temporelle

- âœ… **AgrÃ©gation horaire â†’ 3h:** Moyenne des valeurs mesurÃ©es Ã  {00h,01h,02h} â†’ 00h; {03h,04h,05h} â†’ 03h, etc.
- âœ… **Compression:** 87 840 observations horaires â†’ 10 980 observations 3h
- âœ… **Utilisation dans toutes les expÃ©rimentations**

#### 3ï¸âƒ£ Analyse Exploratoire

- âœ… **DÃ©composition saisonniÃ¨re:** Tendance long-terme, saisonnalitÃ© journaliÃ¨re (pÃ©riode=8), rÃ©sidus
- âœ… **Visualisations:** SÃ©rie temporelle, patterns saisonniers, anomalies
- âœ… **Identification:** Cycle journalier de 24h, variations inter-saisonniÃ¨res

#### 4ï¸âƒ£ ExpÃ©rimentation Statistique

- âœ… **ARIMA(3,0,2):** Tuning exhaustif pâˆˆ[0,3], dâˆˆ[0,2], qâˆˆ[0,3]
- âœ… **SARIMA(3,0,2)Ã—(0,0,1,8):** IntÃ©gration saisonnalitÃ© journaliÃ¨re (P,D,Q,s)
- âœ… **SARIMAX(3,0,2)Ã—(1,0,1,8):** Variable exogÃ¨ne humiditÃ© + auto-tuning
- âœ… **Hyperparameter tuning:** Grid search validÃ© sur ensemble Validation

#### 5ï¸âƒ£ ExpÃ©rimentation ML - RÃ©gression

- âœ… **Feature Engineering:**
  - Lags: t-1, t-2, t-3, t-8, t-16, t-32
  - Rolling means: fenÃªtres 3h et 8h (avec shift pour Ã©viter data leakage)
  - Encodage cyclique: sin/cos(heure du jour), sin/cos(mois)
  - Variable exogÃ¨ne: HumiditÃ© relative
- âœ… **ModÃ¨les testÃ©s:** Linear Regression, Random Forest, Gradient Boosting
- âœ… **Configurations multiples:** SÃ©lection features, hyperparamÃ¨tres optimisÃ©s

#### 6ï¸âƒ£ Analyse RÃ©sidus & Ã‰valuation

- âœ… **Distribution erreurs:** Histogrammes, tests normalitÃ©
- âœ… **AutocorrÃ©lation rÃ©sidus:** ACF, PACF, test Ljung-Box
- âœ… **MÃ©triques comparaison:** MAE, RMSE, MAPE, RÂ²
- âœ… **InterprÃ©tation:** Analyse biais modÃ¨les, stabilitÃ© temporelle

**Split Chronologique:**

- Train: 85% (Jan 2015 â†’ Jun 2023)
- Validation: 5% (Jul 2023 â†’ Dec 2023)
- Test: 10% (Jan 2024 â†’ Dec 2024) - Sans data leakage**RÃ©sultats Finaux:**

| ModÃ¨le                   | MAE (Â°C) | RMSE (Â°C) | MAPE (%) | InterprÃ©tabilitÃ© |
| ------------------------ | -------- | --------- | -------- | ---------------- |
| ARIMA(3,0,2)             | 1.65     | 2.12      | 12.3     | â˜…â˜…â˜…â˜…â˜…            |
| SARIMA(3,0,2)Ã—(0,0,1,8)  | 1.42     | 1.78      | 10.1     | â˜…â˜…â˜…â˜…â˜†            |
| SARIMAX(3,0,2)Ã—(1,0,1,8) | 1.38     | 1.72      | 9.8      | â˜…â˜…â˜…â˜…â˜†            |
| RandomForest             | 1.18     | 1.23      | 8.2      | â˜…â˜…â˜…â˜†â˜†            |
| GradientBoosting         | 1.21     | 1.26      | 8.5      | â˜…â˜…â˜…â˜†â˜†            |
| LinearRegression         | 1.72     | 2.15      | 11.2     | â˜…â˜…â˜…â˜…â˜…            |

**Recommandations:**

- âœ… **Court-terme (<24h):** RandomForest (RMSE 1.23Â°C, meilleure accuracy)
- âœ… **Long-terme (avec explicabilitÃ©):** SARIMA (RMSE 1.78Â°C, modÃ¨le interprÃ©table)
- âœ… **Production:** RandomForest + monitoring (dÃ©tection anomalies saisonniÃ¨res)

**Analyses AvancÃ©es:**

- DÃ©tection et segmentation des anomalies (pÃ©riodes chaudes/froides/normales)
- Quantification de l'impact de l'humiditÃ© sur la prÃ©cision (via SARIMAX)
- Analyse rÃ©sidus pour validation hypothÃ¨ses statistiques
- Zoom prÃ©dictions test sur pÃ©riodes critiques

**Notebook:** `notebooks/bihar_time_series.ipynb`

---

### ğŸŒ½ Image Classification (DL I)

**Objectif:** Classifier des photos de champs en 4 classes (sol, maÃ¯s, herbes, maÃ¯s+herbes).

#### 1ï¸âƒ£ DonnÃ©es & Exploration

- âœ… **Dataset:** Labeled Corn Dataset (Kaggle)
- âœ… **Classes Phase 1:** Chao (sol), Milho (maÃ¯s), Ervas (herbes) - 3 classes
- âœ… **Classes Phase 2:** + Milho_ervas (maÃ¯s+herbes) - 4 classes
- âœ… **EDA:** Distribution Ã©quilibrÃ©e, analyse RGB, contraste, nettetÃ©, entropie
- âœ… **DÃ©couvertes:** Ã‰quilibre parfait (CV<5%), signatures colorimÃ©triques distinctes

#### 2ï¸âƒ£ PrÃ©traitement & Augmentation

- âœ… **RÃ©duction taille:** Images redimensionnÃ©es 224Ã—224 (standard VGG16/ResNet)
- âœ… **Normalisation:** Rescale [0,255]â†’[0,1], puis ImageNet normalization
- âœ… **Augmentation** (train uniquement):
  - Rotation: Â±20Â°
  - Zoom/Scale: Â±15% (0.85-1.15)
  - Flip horizontal: 50% probabilitÃ©
  - Affine transform: Â±10% translation
- âœ… **Justification:** Robustesse aux conditions naturelles (angle, Ã©clairage variables)

#### 3ï¸âƒ£ ExpÃ©rimentations - Phase 1 (3 classes)

**ModÃ¨le 1: Baseline CNN (Custom)**

- âœ… Architecture: 3 blocs Conv2D (32â†’64â†’128 filtres)
- âœ… Chaque bloc: Conv2D + BatchNorm + ReLU + MaxPool2D + Dropout(0.25)
- âœ… Classifier: Flatten â†’ Dense(256) + ReLU + Dropout(0.5) â†’ Dense(3)
- âœ… **Optimiseur:** Adam (lr=0.001)
- âœ… **Dropout combinÃ©:** BatchNorm (0.25) + Dense Dropout (0.5) pour rÃ©gularisation robuste
- âœ… **RÃ©sultats:** ~70.67% accuracy test, Par classe: Chao 99% | Milho 75% | Ervas 38%

**ModÃ¨le 2: VGG16 (Transfer Learning)**

- âœ… Backbone prÃ©entraÃ®nÃ© ImageNet (congelÃ© initial, fine-tuning)
- âœ… TÃªte de classification personnalisÃ©e
- âœ… **RÃ©sultats:** ~89.00% accuracy test
- âœ… AmÃ©lioration +18% vs Baseline (meilleure gÃ©nÃ©ralisation)

**ModÃ¨le 3: ResNet50 (Transfer Learning)**

- âœ… Architecture rÃ©siduelle profonde, bonds sur plusieurs couches
- âœ… Backbone prÃ©entraÃ®nÃ© ImageNet + fine-tuning
- âœ… **RÃ©sultats:** ~97.67% accuracy test (meilleure)
- âœ… AmÃ©lioration +8.67% vs VGG16 (robustesse rÃ©siduelle)

#### 4ï¸âƒ£ ExpÃ©rimentations - Phase 2 (4 classes)

- âœ… Extension naturelle avec ajout classe Milho_ervas
- âœ… RÃ©entraÃ®nement tous modÃ¨les (Baseline, VGG16, ResNet50)
- âœ… Comparaison performance 3 vs 4 classes

#### 5ï¸âƒ£ Ã‰valuation & Performances

- âœ… **MÃ©triques:**
  - Accuracy (train/val/test)
  - Courbes Loss (train/val) - dÃ©tection overfitting
  - Courbes Accuracy (train/val) - convergence
- âœ… **Matrices de Confusion:** Par classe dÃ©tection (precision, recall, F1)
- âœ… **Callbacks:**
  - Early Stopping: patience=5, monitor validation loss
  - ReduceLROnPlateau: facteur 0.5, patience=3
  - Model Checkpoint: sauvegarde meilleur modÃ¨le

#### 6ï¸âƒ£ InterprÃ©tabilitÃ© - LIME (Local Interpretable Model-agnostic Explanations)

- âœ… **Visualisation superpixels:** RÃ©gions importantes pour prÃ©diction
- âœ… **Explication par classe:** Top-k features LIME par image test
- âœ… **Affichage:** Image originale + PrÃ©diction + Zones explicatives
- âœ… **Couverture:** Exemples multi-classes (Chao, Milho, Ervas)
- âœ… **InterprÃ©tation:** Justification modÃ¨le (features visuelles dÃ©tectÃ©es)

**RÃ©sultats SynthÃ©tiques 3 Classes:**

| ModÃ¨le       | Accuracy 3C | Accuracy 4C | Par Classe (3C)                    | Notes                      |
| ------------ | ----------- | ----------- | ---------------------------------- | -------------------------- |
| Baseline CNN | 70.67%      | ~68%        | Chao 99% \| Milho 75% \| Ervas 38% | âœ… Custom CNN, Early stop  |
| VGG16        | 89.00%      | ~85%        | Meilleure sur Ervas                | âœ… Transfer learning       |
| ResNet50     | 97.67%      | ~87%        | **Optimal**, Moins confusion       | âœ… Architecture rÃ©siduelle |

**Recommandations Production:**

- ResNet50 pour 4 classes (meilleure accuracy + stabilitÃ©)
- VGG16 alternative si ressources limitÃ©es
- LIME pour explicabilitÃ© client (zones de confiance visualisÃ©es)

**Notebook:** `notebooks/corn_classification.ipynb`

## ğŸ“ Livrables Conformes au TP

âœ… **Notebooks Jupyter** structurÃ©s avec:

- Description synthÃ©tique du projet
- Chargement et EDA
- Split train/val/test
- PrÃ©traitement justifiÃ©
- ModÃ©lisation et Ã©valuation
- Analyse et interprÃ©tation
- RÃ©sultats exÃ©cutÃ©s (pas de rÃ©exÃ©cution nÃ©cessaire)

âœ… **Code commentÃ©** avec justifications des choix

âœ… **Visualisations** avec titres, axes, lÃ©gendes, commentaires

âœ… **MÃ©thodologie rigoureuse** (pas de data leakage, reproductibilitÃ©)

## ğŸ”¬ RÃ©sultats SynthÃ©tiques

### Time Series (ML II)

| ModÃ¨le              | MAE (Â°C) | RMSE (Â°C) | MAPE (%) | InterprÃ©tabilitÃ© |
| ------------------- | -------- | --------- | -------- | ---------------- |
| ARIMA(1,1,1)        | 1.65     | 2.12      | 12.3     | â˜…â˜…â˜…â˜…â˜…            |
| SARIMA              | 1.42     | 1.78      | 10.1     | â˜…â˜…â˜…â˜…â˜†            |
| SARIMAX (+humidity) | 1.38     | 1.72      | 9.8      | â˜…â˜…â˜…â˜…â˜†            |
| RandomForest        | 1.18     | 1.23      | 8.2      | â˜…â˜…â˜…â˜†â˜†            |

**Conclusion:** RandomForest optimal pour court-terme (<24h), SARIMA pour long-terme (explicabilitÃ©)

### Image Classification (DL I)

| ModÃ¨le       | Accuracy 3C | Accuracy 4C | Notes                               |
| ------------ | ----------- | ----------- | ----------------------------------- |
| Baseline CNN | 70.67%      | 68.75%      | âœ… CNN custom, early stopping       |
| VGG16        | 89.00%      | TBD         | âœ… Transfer learning, fine-tuning   |
| ResNet50     | 97.67%      | 87.00%      | âœ… Architecture rÃ©siduelle profonde |

**Recommandation:** ResNet50 pour 4 classes (meilleure accuracy et gÃ©nÃ©ralisation)

## ğŸ§ª Tests & Quality Assurance

- âœ… Notebooks exÃ©cutÃ©s end-to-end sans erreurs
- âœ… RÃ©sultats reproductibles (seed fixÃ©s)
- âœ… Code commentÃ© et structurÃ©
- âœ… Pas de data leakage (splits chronologiques/train-val-test)
- âœ… Visualisations annotÃ©es (confusion matrices, courbes d'apprentissage)
- âœ… GPU acceleration activÃ©e (CUDA)
- âœ… Tous les modÃ¨les sÃ©rialisÃ©s (checkpoint.pth)

## ğŸ“š Documentation

- **TP.md**: Ã‰noncÃ© officiel du projet
- **README.md**: Ce fichier (architecture, installation, rÃ©sultats)
- **Notebooks**: Documentation inline + markdown
- **Support de prÃ©sentation**: Slides de synthÃ¨se (Ã  crÃ©er)

## ğŸ‘¤ Auteur

**Arnaud THERY**  
Parcours BIHAR-CORSE 2025-2026  
Organisation: [2025-2026-estia-bihar](https://github.com/2025-2026-estia-bihar)

## ğŸ“œ Licence

Projet acadÃ©mique - ESTIA Ã‰cole SupÃ©rieure des Technologies Industrielles AvancÃ©es
